#stuff seems like the best approaches for many use cases 
#---------------stuff
# we are taking the relevant {fact} and the {question} and 'stuffing' them into SystemMessagePromptTemplate and HumanMessagePromptTemplate within the ChatPromptTemplate


#---------------map_reduce
#NOTE calls the language model multiple times, in this case five times. 
#NOTE: Issues with this type: sometimes CGPT will 'make up' facts on the spot if the document doesn't contain any relevant information to the question, instead of "no relevant info"
#steps:
# 1) Takes the first 'document' with relevant embeddings and puts it inside a SystemMessagePromptTemplate:
    # -Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim {content}
    # in the same chain it also has the HumanMessagePromptTemplate: Here is the user's question {question}
# 2) does this for each of the four documents 
# 3) all four of the final summaries (answers) from the first pass-through are then ran through once more with the same stype of prompttemplate to get the final answer
#for debugging this type, import langchain; then first line set langchain.debug=True


#---------------map_reank
# Similar to MapReduce, but with a difference. The HumanMessagePromptTemplate says ~"Use the following pieces of context to answer the question at the end. 
# In addition to giving an answer, also return a score of how fully it answered the user's question. {content}"
#NOTE Issues with this type: the scoring *could* still 'make up' the facts but it might still give that made up fact a score of 100. 


#---------------refine
#steps: 
# 1) Takes the four relevant documents from the vector store
# 2) feeds them into their own chain of SystemMessagePromptTemplate ("use the following context to answer the question {context}") 
    # and HumanMessagePromptTemplate("here is the user's question {question}") before sending to LLMChain
# 3) takes the answer from the first chain, combines the answer from the first output and the new context into a new chain    
    #  {context} + {question} >> output
    # human + AIMessagePromptTemplate{answer from previous step} + optionToRefineAnswerWithAdditionalContext HumanMessagePromptTemplate{Context} >> output 
# NOTE: since the potential last piece of information may not be relevant at all, the final return output might say "The added context was not relevant"


